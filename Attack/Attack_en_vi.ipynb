{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"program\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en2vi_source_embed_dim=512-source_hidden_size=512-source_rnn_layers=2-source_rnn_type=lstm-target_embed_dim=512-target_hidden_size=1024-target_rnn_layers=2-attention=True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "path_to_helper_files = os.path.join('..', 'py_files')\n",
    "base_saved_models_dir = os.path.join('..', 'saved_models' )\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(path_to_helper_files)\n",
    "\n",
    "\n",
    "import global_variables\n",
    "import dataset_helper\n",
    "import nnet_models\n",
    "import train_utilities\n",
    "\n",
    "device = global_variables.device;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "source_name = 'en'\n",
    "target_name = 'vi'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAX_LEN = 48\n",
    "batchSize = 128\n",
    "\n",
    "\n",
    "source_rnn_type  = 'lstm'\n",
    "\n",
    "\n",
    "\n",
    "attention = True\n",
    "\n",
    "\n",
    "\n",
    "embed_dim_array = [512]\n",
    "rnn_layers_array = [2]\n",
    "\n",
    "for embed_dim in embed_dim_array:\n",
    "\tfor rnn_layers in rnn_layers_array:\n",
    "\n",
    "\t\tsource_embed_dim = embed_dim\n",
    "\t\tsource_hidden_size = embed_dim\n",
    "\n",
    "\t\ttarget_embed_dim= embed_dim\n",
    "\t\ttarget_hidden_size = 2*embed_dim\n",
    "\t\tsource_rnn_layers = rnn_layers\n",
    "\t\ttarget_rnn_layers = rnn_layers\n",
    "\n",
    "\n",
    "\t\tif source_name == 'en' and target_name == 'vi':\n",
    "\t\t\t\tsource_train_path = '../Data/iwslt-vi-en/train.tok.en'\n",
    "\t\t\t\ttarget_train_path = '../Data/iwslt-vi-en/train.tok.vi'\n",
    "\n",
    "\t\t\t\tsource_val_path = '../Data/iwslt-vi-en/dev.tok.en'\n",
    "\t\t\t\ttarget_val_path = '../Data/iwslt-vi-en/dev.tok.vi'\n",
    "\n",
    "\t\t\t\tsource_test_path = '../Data/iwslt-vi-en/test.tok.en'\n",
    "\t\t\t\ttarget_test_path = '../Data/iwslt-vi-en/test.tok.vi'\n",
    "\n",
    "\t\t# elif source_name == 'zh' and target_name == 'en':\n",
    "\t\t# \t\ttarget_train_path = '../Data/iwslt-zh-en/train.tok.en'\n",
    "\t\t# \t\tsource_train_path = '../Data/iwslt-zh-en/train.tok.zh'\n",
    "        #\n",
    "\t\t# \t\ttarget_val_path = '../Data/iwslt-zh-en/dev.tok.en'\n",
    "\t\t# \t\tsource_val_path = '../Data/iwslt-zh-en/dev.tok.zh'\n",
    "        #\n",
    "\t\t# \t\ttarget_test_path = '../Data/iwslt-zh-en/test.tok.en'\n",
    "\t\t# \t\tsource_test_path = '../Data/iwslt-zh-en/test.tok.zh'\n",
    "\t\telse:\n",
    "\t\t\t\tsys.exit(source_name+'->'+target_name+' is invalid!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tsaved_models_dir = os.path.join(base_saved_models_dir, source_name+'2'+target_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tpth_save_folder_name = source_name+'2'+target_name+'_' + \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'source_embed_dim='+str(source_embed_dim) +  \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'-source_hidden_size='+str(source_hidden_size) +  \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'-source_rnn_layers=' + str(source_rnn_layers) + \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'-source_rnn_type='+str(source_rnn_type)+ \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'-target_embed_dim='+str(target_embed_dim) + \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'-target_hidden_size='+str(target_hidden_size) + \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'-target_rnn_layers='+str(target_rnn_layers) + \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t'-attention='+str(attention);\n",
    "\t\tpth_saved_dir = os.path.join(saved_models_dir, pth_save_folder_name)\n",
    "\n",
    "\n",
    "\n",
    "\t\tprint(pth_save_folder_name)\n",
    "\t\tsys.stdout.flush()\n",
    "\n",
    "\t\tsaved_language_model_dir = os.path.join(saved_models_dir, 'lang_obj')\n",
    "\n",
    "\n",
    "\n",
    "\t\tdataset_dict = {'train': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_path = source_train_path, target_path = target_train_path, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlang_obj_path = saved_language_model_dir), \n",
    "\n",
    "\t\t\t\t\t \t'val': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_path = source_val_path, target_path = target_val_path, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlang_obj_path = saved_language_model_dir, val = True), \n",
    "\n",
    "\t\t\t\t\t\t'test': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsource_path = source_test_path, target_path = target_test_path, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlang_obj_path = saved_language_model_dir, val = True)}\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tdataloader_dict = {'train': DataLoader(dataset_dict['train'], batch_size = batchSize, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcollate_fn = partial(dataset_helper.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle = True, num_workers=0), \n",
    "\t\t\t\t\t\t\t\t\t\t\t'val': DataLoader(dataset_dict['val'], batch_size = 1, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcollate_fn = dataset_helper.vocab_collate_func_val,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle = True, num_workers=0), \n",
    "\t\t\t\t\t\t\t\t\t\t\t'test': DataLoader(dataset_dict['test'], batch_size = 1, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcollate_fn = dataset_helper.vocab_collate_func_val,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle = True, num_workers=0)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tencoder = nnet_models.EncoderRNN(dataset_dict['train'].source_lang_obj.n_words, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t embed_dim = source_embed_dim, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t hidden_size = source_hidden_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t rnn_layers = source_rnn_layers, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t rnn_type = source_rnn_type).to(device);\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tdecoder = nnet_models.DecoderRNN(dataset_dict['train'].target_lang_obj.n_words, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tembed_dim = target_embed_dim, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thidden_size = target_hidden_size, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tn_layers = target_rnn_layers, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tattention = attention).to(device)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tencoder_optimizer = optim.SGD(encoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "\t\tenc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-4,  patience=0)\n",
    "\t\tdecoder_optimizer = optim.SGD(decoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "\t\tdec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-4,  patience=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tcriterion = nn.NLLLoss(ignore_index = global_variables.PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab Size\n",
    "V = dataset_dict['train'].target_lang_obj.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13294"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirc = 'en2vi_source_embed_dim=512-source_hidden_size=512-source_rnn_layers=2-source_rnn_type=lstm-target_embed_dim=512-target_hidden_size=1024-target_rnn_layers=2-attention=True'\n",
    "encoder_name = os.path.join('..','saved_models', 'en2vi',dirc,'encoder.pth')\n",
    "decoder_name = os.path.join('..','saved_models', 'en2vi',dirc,'decoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_state_dict(torch.load(encoder_name))\n",
    "decoder.load_state_dict(torch.load(decoder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader_dict['test'].sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = global_variables.SOS_token\n",
    "EOS_token = global_variables.EOS_token\n",
    "UNK_IDX = global_variables.UNK_IDX\n",
    "PAD_IDX = global_variables.PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack BLEU: 5.471814773996189\n",
      "Total Number of Words Changing: 135\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_change = 0\n",
    "loss_fun = nn.NLLLoss(ignore_index = global_variables.PAD_IDX)\n",
    "true_corpus = []\n",
    "pred_corpus = []\n",
    "count = 0\n",
    "sample = []\n",
    "sample_size = 20\n",
    "SAMPLE = True\n",
    "for data in dataloader_dict['test']:\n",
    "    count += 1\n",
    "    for param in encoder.parameters():\n",
    "        if param.grad is not None:\n",
    "            param.grad.data.zero_()\n",
    "    encoder_i = data[0].to(device)\n",
    "    decoder_i = data[1].to(device)\n",
    "    src_len = data[2].to(device)\n",
    "    tar_len = data[3].to(device)    \n",
    "    rm = 0\n",
    "    out = train_utilities.encode_decode(encoder, decoder, encoder_i,decoder_i,src_len,tar_len, rand_num=rm, val = False )\n",
    "    loss = loss_fun(out.float(), decoder_i.long() )\n",
    "    loss.backward()\n",
    "    craft_encoder_i = encoder_i.clone()\n",
    "    for j in range(len(encoder_i[0])):\n",
    "        cur_data = encoder_i[0][j]\n",
    "        if cur_data == global_variables.PAD_IDX:\n",
    "            break\n",
    "        # get the grad\n",
    "        grad_j = encoder.embedding.weight.grad[cur_data]\n",
    "        # get synonym                \n",
    "        temp = src_lang.index2word[cur_data]\n",
    "        syns = wordnet.synsets(temp) \n",
    "        max_cor = 0\n",
    "        flag_change = 0\n",
    "        for syn in syns:\n",
    "            for temp2 in syn.lemmas():\n",
    "                temp3 = temp2.name()\n",
    "                if temp3 in aset or temp3 == temp:\n",
    "                    continue\n",
    "                elif temp3 in src_lang.word2index.keys():\n",
    "                    temp4 = src_lang.word2index[temp3]\n",
    "                    attack_embed = encoder.embedding.weight[temp4]\n",
    "                    cur_embed = encoder.embedding.weight[cur_data]\n",
    "                    cur_cor = torch.sum(grad_j*(attack_embed-cur_embed))\n",
    "                    if cur_cor > max_cor:\n",
    "                        flag_change = 1\n",
    "                        max_cor = cur_cor\n",
    "                        craft_encoder_i[0][j] = temp4\n",
    "        if flag_change == 1:\n",
    "            total_change += 1\n",
    "    if count <=sample_size:\n",
    "        sample.append([train_utilities.convert_id_list_2_sent(encoder_i[0],src_lang),train_utilities.convert_id_list_2_sent(craft_encoder_i[0],src_lang) ])\n",
    "    elif SAMPLE:\n",
    "        break\n",
    "    # Evaluate\n",
    "    bs,sl = encoder_i.size()[:2]\n",
    "    en_out,en_hid,en_c = encoder(craft_encoder_i,src_len)\n",
    "    prev_hiddens = en_hid\n",
    "    prev_cs = en_c\n",
    "    decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "    prev_output = torch.zeros((bs, en_out.size(-1))).to(device)\n",
    "    d_out = []\n",
    "    for i in range(sl*2):\n",
    "        out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                src_len)\n",
    "        topv, topi = out_vocab.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "        d_out.append(topi.item())\n",
    "        decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "        if topi.item() == EOS_token:\n",
    "            break\n",
    "    true_corpus.append(data[-1])\n",
    "    pred_sent = train_utilities.convert_id_list_2_sent(d_out,tgt_lang)\n",
    "    pred_corpus.append(pred_sent)\n",
    "from bleu_score import BLEU_SCORE\n",
    "bl = BLEU_SCORE()\n",
    "score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "print('Attack BLEU:', score)\n",
    "print('Total Number of Words Changing:', total_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack BLEU: 10.454769418796282\n",
      "Total Number of Words Changing: 0\n"
     ]
    }
   ],
   "source": [
    "# projected and fix the number\n",
    "total_change = 0\n",
    "loss_fun = nn.NLLLoss(ignore_index = global_variables.PAD_IDX)\n",
    "true_corpus = []\n",
    "pred_corpus = []\n",
    "count = 0\n",
    "sample = []\n",
    "sample_size = 20\n",
    "SAMPLE = False\n",
    "per = 2\n",
    "for data in dataloader_dict['test']:\n",
    "    count += 1\n",
    "    encoder_i = data[0].to(device)\n",
    "    decoder_i = data[1].to(device)\n",
    "    src_len = data[2].to(device)\n",
    "    tar_len = data[3].to(device)    \n",
    "    rm = 0\n",
    "    craft_encoder_i = encoder_i.detach().clone()\n",
    "    num_round = np.max((src_len//per,1))\n",
    "    for _ in range(num_round):\n",
    "        for param in encoder.parameters():\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.zero_()\n",
    "        max_cor = 0\n",
    "        max_idx = -1\n",
    "        out = train_utilities.encode_decode(encoder, decoder, craft_encoder_i,decoder_i,src_len,tar_len, rand_num=rm, val = False )\n",
    "        loss = loss_fun(out.float(), decoder_i.long() )\n",
    "        loss.backward()\n",
    "        for j in range(len(craft_encoder_i[0])):\n",
    "            cur_data = craft_encoder_i[0][j]\n",
    "            if cur_data == global_variables.PAD_IDX:\n",
    "                break\n",
    "            # get the grad\n",
    "            grad_j = encoder.embedding.weight.grad[cur_data]\n",
    "            # get synonym                \n",
    "            temp = src_lang.index2word[cur_data]\n",
    "            syns = wordnet.synsets(temp) \n",
    "#             flag_change = 0\n",
    "            for syn in syns:\n",
    "                for temp2 in syn.lemmas():\n",
    "                    temp3 = temp2.name()\n",
    "                    if temp3 in aset or temp3 == temp:\n",
    "                        continue\n",
    "                    elif temp3 in src_lang.word2index.keys():\n",
    "                        temp4 = src_lang.word2index[temp3]\n",
    "                        attack_embed = encoder.embedding.weight[temp4]\n",
    "                        cur_embed = encoder.embedding.weight[cur_data]\n",
    "                        cur_cor = torch.sum(grad_j*(attack_embed-cur_embed))\n",
    "                        if cur_cor > max_cor:\n",
    "                            max_idx = j\n",
    "                            max_cor = cur_cor\n",
    "                            max_cnd = temp4\n",
    "        if max_idx != -1:\n",
    "            craft_encoder_i[0][max_idx] = max_cnd\n",
    "            craft_encoder_i = craft_encoder_i.detach().clone()\n",
    "        else:\n",
    "            break\n",
    "#         if flag_change == 1:\n",
    "#             total_change += 1\n",
    "    if count <=sample_size:\n",
    "        sample.append([train_utilities.convert_id_list_2_sent(encoder_i[0],src_lang),train_utilities.convert_id_list_2_sent(craft_encoder_i[0],src_lang) ])\n",
    "    elif SAMPLE:\n",
    "        break\n",
    "    # Evaluate\n",
    "    bs,sl = encoder_i.size()[:2]\n",
    "    en_out,en_hid,en_c = encoder(craft_encoder_i,src_len)\n",
    "    prev_hiddens = en_hid\n",
    "    prev_cs = en_c\n",
    "    decoder_input = torch.tensor([[SOS_token]]*bs).to(device)\n",
    "    prev_output = torch.zeros((bs, en_out.size(-1))).to(device)\n",
    "    d_out = []\n",
    "    for i in range(sl*2):\n",
    "        out_vocab, prev_output,prev_hiddens, prev_cs, attention_score = decoder(decoder_input,prev_output, \\\n",
    "                                                                                prev_hiddens,prev_cs, en_out,\\\n",
    "                                                                                src_len)\n",
    "        topv, topi = out_vocab.topk(1)\n",
    "#             decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "        d_out.append(topi.item())\n",
    "        decoder_input = topi.squeeze().detach().view(-1,1)\n",
    "        if topi.item() == EOS_token:\n",
    "            break\n",
    "    true_corpus.append(data[-1])\n",
    "    pred_sent = train_utilities.convert_id_list_2_sent(d_out,tgt_lang)\n",
    "    pred_corpus.append(pred_sent)\n",
    "from bleu_score import BLEU_SCORE\n",
    "bl = BLEU_SCORE()\n",
    "score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "print('Attack BLEU:', score)\n",
    "print('Total Number of Words Changing:', total_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['so back in the day , when us indians wanted to travel we &apos;d jump into a UNK and we &apos;d zoom across the sky .',\n",
       "  'then support inch the daylight , when us indians desire to travel we &apos;d leap into a UNK and we &apos;d zoom across the toss .'],\n",
       " ['it &apos;s just really about combining different realities .',\n",
       "  'it &apos;s just very around combine unlike reality .'],\n",
       " ['at one point , your screen is filled up with leaves .',\n",
       "  'at single charge , your test exist satisfy improving with provide .'],\n",
       " ['and those are the neural structures .',\n",
       "  'and those equal the neural structure .'],\n",
       " ['and i was shocked and UNK to the core .',\n",
       "  'and one be shock and UNK to the center .'],\n",
       " ['and yet , we have in this country this dynamic where we really don &apos;t like to talk about our problems .',\n",
       "  'and even , we consume inch this nation this active where we genuinely father &apos;t wish to babble around our trouble .'],\n",
       " ['and of course , we can never have the death penalty in germany . &quot;',\n",
       "  'and of form , we can never own the demise penalty in germany . &quot;'],\n",
       " ['and i &apos;ve got here a little 100 UNK of white powder , which i try not to let the security people see at airports .',\n",
       "  'and 1 &apos;ve stimulate here amp small c UNK of white powder , which 1 prove not to get the security masses realize at airport .'],\n",
       " ['because it &apos;s in that UNK that we actually begin to understand truly profound things about who we are .',\n",
       "  'because it &apos;s inch that UNK that we actually start to understand truly heavy things around who we live .'],\n",
       " ['and assistant prosecutors and UNK workers .',\n",
       "  'and assistant prosecutors and UNK worker .'],\n",
       " ['now if i look at those programs , i can &apos;t tell you how they work .',\n",
       "  'today if i seem at those plan , i can &apos;t say you how they run .'],\n",
       " ['and i memorized everything .', 'and single memorize everything .'],\n",
       " ['here i have a very complicated , messy , confused idea in my head .',\n",
       "  'here ace accept amp identical elaborate , messy , fox estimate in my direct .'],\n",
       " ['thank you .', 'thank you .'],\n",
       " ['and she said the three words : do you remember ?',\n",
       "  'and she read the leash password : perform you recall ?'],\n",
       " ['eight years ago when i was at the media lab , i started exploring this idea of how to put the power of engineers in the hands of artists and designers .',\n",
       "  'eight year ago when one be at the medium lab , one initiate explore this thought of how to invest the king of technologist inch the hand of artists and designer .'],\n",
       " ['so the things that make a photograph look realistic , i think it &apos;s the things that we don &apos;t even think about , the things all around us in our daily lives .',\n",
       "  'then the thing that build a photograph see realistic , ace suppose it &apos;s the thing that we wear &apos;t eve suppose some , the thing all round us in our casual animation .'],\n",
       " ['i even knew the differential diagnosis in how to classify UNK UNK UNK .',\n",
       "  '1 evening live the differential diagnosis inch how to separate UNK UNK UNK .'],\n",
       " ['what you find is the people who go from high choice to low choice , they &apos;re hitting that default button over and over and over again .',\n",
       "  'what you see follow the people who last from heights quality to blue quality , they &apos;re reach that default clitoris complete and complete and complete again .'],\n",
       " ['and do we trust , do we blindly trust , any future government , a government we might have 50 years from now ?',\n",
       "  'and exercise we bank , exercise we blindly bank , whatsoever future governance , amp governance we might accept l age from now ?']]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 29536\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for data in dataloader_dict['test']:\n",
    "    for param in encoder.parameters():\n",
    "        if param.grad is not None:\n",
    "            param.grad.data.zero_()\n",
    "    encoder_i = data[0].to(device)\n",
    "    decoder_i = data[1].to(device)\n",
    "    src_len = data[2].to(device)\n",
    "    tar_len = data[3].to(device)    \n",
    "    rm = 0\n",
    "#     out = train_utilities.encode_decode(encoder, decoder, encoder_i,decoder_i,src_len,tar_len, rand_num=rm, val = False )\n",
    "#     loss = loss_fun(out.float(), decoder_i.long() )\n",
    "#     loss.backward()\n",
    "#     craft_encoder_i = encoder_i.clone()\n",
    "    for j in range(len(encoder_i[0])):\n",
    "        cur_data = encoder_i[0][j]\n",
    "        if cur_data == global_variables.PAD_IDX:\n",
    "            break\n",
    "    count += j+1\n",
    "print('Count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 percent\n",
    "Attack BLEU: 16.074000340008755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 percent\n",
    "Attack BLEU: 13.536007353319993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 percent\n",
    "Attack BLEU: 11.79593366133339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 percent\n",
    "Attack BLEU: 10.41698616667105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1553"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader_dict['test'].sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attack BLEU: 5.6308264661308165\n",
    "Total Number of Words Changing: 10967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['you guys knew there was a trick , didn &apos;t you .',\n",
       "  'you rib knew there was a illusion , didn &apos;t you .'],\n",
       " ['what does this mean ?', 'what does this believe ?'],\n",
       " ['so in bringing back this childhood ritual , you need to go out and , in one chapter , take a picture of a flower and then tag it .',\n",
       "  'so in operate back this childhood ritual , you need to go out and , in one chapter , take a see of a account and then delete it .'],\n",
       " ['i gave her my whole rap , and when i finished she looked at me and she said , &quot; mmm mmm mmm . &quot;',\n",
       "  'one afford her my whole pink , and when i part she count at me and she tell , &quot; mmm mmm mmm . &quot;'],\n",
       " ['so i felt like our cellphones and our fancy watches and our cameras had stopped us from dreaming .',\n",
       "  'so i felt like our cellphones and our fancy believe and our cameras had stopped us from dream .'],\n",
       " ['but , but , you know what ?', 'but , but , you know what ?'],\n",
       " ['and he was here , as you well know , in &apos; 35 .',\n",
       "  'and he equal here , as you well lay , in &apos; 35 .'],\n",
       " ['and so i did .', 'and so i did .'],\n",
       " ['the third one is about making it impossible to distinguish where the different images begin and end by making it UNK .',\n",
       "  'the third one is about have it impossible to tell where the different icon begin and destruction by cause it UNK .'],\n",
       " ['and sure , we could find fast food chains .',\n",
       "  'and sure , we could find fast food force .'],\n",
       " ['and i put in my motion that there was UNK UNK and police UNK and judicial UNK .',\n",
       "  'and i gift in my run that there was UNK UNK and police UNK and judicial UNK .'],\n",
       " ['in many communities , people had to worry about being UNK .',\n",
       "  'in many community , people had to concern about being UNK .'],\n",
       " ['who are they actually supposed to be informing ?',\n",
       "  'who are they actually imagine to cost inform ?'],\n",
       " ['so what was the next step ?', 'so what was the succeeding abuse ?'],\n",
       " ['i &apos;ve come to understand and to believe that each of us is more than the worst thing we &apos;ve ever done .',\n",
       "  'i &apos;ve office to understand and to believe that each of us is more than the tough thing we &apos;ve ever done .'],\n",
       " ['so to achieve a realistic result , i think it comes down to planning .',\n",
       "  'so to reach a realistic reply , i think it comes down to planning .'],\n",
       " ['do you know how many choices make it into your nine minute category versus your one hour category ?',\n",
       "  'do you know how many pick make it into your club number family versus your one hour category ?'],\n",
       " ['he talked to the family , and i &apos;m quite sure that he UNK things over and made sure that i didn &apos;t get sued .',\n",
       "  'he talked to the brand , and i &apos;m quite certain that he UNK things over and made certain that i didn &apos;t get action .'],\n",
       " ['somehow this isn &apos;t working .', 'somehow this isn &apos;t mold .'],\n",
       " ['i represent children .', 'i present children .']]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack BLEU: 5.809777537335008\n",
      "Total Number of Words Changing: 29536\n"
     ]
    }
   ],
   "source": [
    "from bleu_score import BLEU_SCORE\n",
    "bl = BLEU_SCORE()\n",
    "score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]\n",
    "print('Attack BLEU:', score)\n",
    "print('Total Number of Words Changing:', total_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = bl.corpus_bleu(pred_corpus,[true_corpus],lowercase=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.max(src_lang.word2index.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16031"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_syns = 0\n",
    "for data in dataloader_dict['test']:\n",
    "    for i in range(len(data[0][0])):\n",
    "        temp = src_lang.index2word[data[0][0][i]]\n",
    "        syns = wordnet.synsets(temp) \n",
    "        aset = []\n",
    "        for syn in syns:\n",
    "            for temp2 in syn.lemmas():\n",
    "                if temp2.name() in aset or temp2.name() == temp:\n",
    "                    continue\n",
    "                elif temp2.name() in src_lang.word2index.keys():\n",
    "                    aset.append(temp2.name())\n",
    "        total_syns += len(aset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106535"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "full_file_path = '../saved_models/en2vi/lang_obj/'\n",
    "src_lang = pickle.load(open( full_file_path+'en_lang_obj_min_count_5.p', \"rb\" ))\n",
    "tgt_lang = pickle.load(open( full_file_path+'vi_lang_obj_min_count_5.p', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1967,  0.0354,  0.5990,  0.1275,  0.0795, -0.0349, -0.1683, -0.0733,\n",
       "         0.2683,  0.3148, -0.2220,  0.0449,  0.3622, -0.0465,  0.4183,  0.0299,\n",
       "        -0.0609,  0.0571, -0.0192, -0.2702,  0.4174,  0.0935,  0.0809,  0.0201,\n",
       "        -0.1079, -0.1266, -0.2213, -0.0410,  0.1821,  0.3677, -0.0266,  0.1970,\n",
       "        -0.0603, -0.0875,  0.4555,  0.2120, -0.0858, -0.0746,  0.2114,  0.0861,\n",
       "        -0.0805,  0.2562, -0.3957,  0.0392,  0.2104, -0.1347, -0.0575, -0.0196,\n",
       "         0.0566,  0.1692, -0.1209,  0.0712,  0.1968, -0.2708, -0.1913, -0.2343,\n",
       "         0.0930,  0.0778, -0.0575, -0.0630, -0.1630, -0.1435, -0.1506,  0.4511,\n",
       "         0.2082,  0.0410, -0.0060, -0.0203, -0.3231, -0.1152, -0.1980, -0.0155,\n",
       "        -0.0989,  0.0861,  0.2005,  0.0113,  0.0896,  0.0330,  0.1863, -0.1990,\n",
       "         0.2495,  0.0224,  0.2144,  0.2792,  0.1894, -0.0424, -0.2009,  0.2091,\n",
       "         0.1105, -0.1611, -0.1534, -0.1628, -0.0760,  0.0740, -0.2061, -0.2411,\n",
       "        -0.0542,  0.3449, -0.0645,  0.0929,  0.0030,  0.2804,  0.2613,  0.1593,\n",
       "        -0.2333, -0.2456,  0.2218,  0.2852, -0.0189,  0.1864,  0.3169, -0.1627,\n",
       "         0.1738,  0.3418, -0.0766, -0.1116, -0.0014,  0.3419, -0.0390,  0.1019,\n",
       "        -0.1231,  0.0053,  0.0426,  0.0262, -0.3522, -0.0101,  0.0087,  0.2027,\n",
       "         0.1029,  0.1630,  0.0665,  0.0580, -0.1805, -0.3074, -0.1831,  0.1944,\n",
       "         0.0935,  0.1306,  0.0342,  0.0784, -0.0072, -0.1554,  0.0450, -0.2842,\n",
       "        -0.1652, -0.1973, -0.0903,  0.0383, -0.2410, -0.2011, -0.2123,  0.0880,\n",
       "        -0.3448,  0.1204,  0.0499, -0.2264, -0.3750,  0.1299,  0.2520,  0.0022,\n",
       "        -0.0534, -0.2731,  0.0825, -0.0300,  0.0718,  0.1947,  0.0844, -0.1551,\n",
       "         0.0408, -0.1680,  0.0295,  0.1540,  0.2729,  0.1521,  0.0264, -0.1888,\n",
       "        -0.0246, -0.2508, -0.2142,  0.0403, -0.0644, -0.3573, -0.1486, -0.1547,\n",
       "         0.0435,  0.1102, -0.4579,  0.1004, -0.1624,  0.2311,  0.1349,  0.0617,\n",
       "        -0.4704,  0.4043,  0.0978, -0.1394,  0.0812,  0.1442, -0.0010, -0.4954,\n",
       "        -0.3206, -0.0664,  0.0261, -0.0689,  0.1927,  0.4277, -0.1939, -0.0759,\n",
       "         0.3048, -0.3719, -0.0644,  0.3137, -0.1022,  0.0571, -0.1604,  0.0732,\n",
       "        -0.0433, -0.0694, -0.2473, -0.1988, -0.2978,  0.0558, -0.1441,  0.0275,\n",
       "         0.1129,  0.1033,  0.0300, -0.0466, -0.1188,  0.2148, -0.0467, -0.1451,\n",
       "        -0.0717,  0.0752, -0.1558,  0.2893,  0.3258,  0.3020, -0.0270, -0.1808,\n",
       "        -0.0897,  0.2308, -0.0803,  0.1475,  0.1401, -0.0256, -0.0663,  0.0324,\n",
       "        -0.4289, -0.1579,  0.2127, -0.5206, -0.0540,  0.6532,  0.1085, -0.2716,\n",
       "        -0.1001,  0.1576, -0.1230,  0.2446,  0.1547,  0.0244, -0.0764, -0.3119,\n",
       "        -0.1324,  0.1350,  0.1078, -0.0838, -0.1175,  0.0721,  0.0006, -0.3459,\n",
       "        -0.0375,  0.1067,  0.0731,  0.1590,  0.1597, -0.2940, -0.0546,  0.4921,\n",
       "         0.1327,  0.2755,  0.0108, -0.0007, -0.1230,  0.0452, -0.0844,  0.0874,\n",
       "         0.0110, -0.2357,  0.0022, -0.1727, -0.0506,  0.0415,  0.1157,  0.2595,\n",
       "         0.2837,  0.1792,  0.0818,  0.0702, -0.0482, -0.0009, -0.0364,  0.0750,\n",
       "        -0.2453,  0.3765, -0.0745, -0.2849, -0.3679,  0.1114, -0.1092,  0.1166,\n",
       "        -0.1205,  0.0527,  0.0193, -0.4398,  0.2382, -0.1033,  0.0000, -0.2139,\n",
       "         0.4725, -0.0984,  0.3850, -0.0423, -0.3607,  0.0280, -0.2297,  0.1470,\n",
       "         0.2504,  0.2293,  0.0246, -0.1552, -0.0891,  0.0218, -0.1298, -0.3623,\n",
       "         0.0001, -0.0827, -0.1522, -0.2855, -0.1851,  0.1941, -0.1140,  0.0391,\n",
       "         0.1127,  0.0762, -0.1362, -0.0989, -0.0980, -0.0259,  0.0123, -0.2127,\n",
       "         0.0104, -0.0026, -0.0676, -0.0850,  0.0430, -0.4012, -0.4821,  0.4600,\n",
       "         0.1565,  0.0927,  0.0744, -0.1397,  0.2431,  0.1803,  0.3088, -0.1116,\n",
       "        -0.2422, -0.0777,  0.2186,  0.0044, -0.1485, -0.0406, -0.0001,  0.2997,\n",
       "        -0.0231, -0.3681, -0.2640, -0.1789, -0.0492,  0.2110,  0.3192, -0.1560,\n",
       "        -0.1511, -0.0170, -0.1395, -0.1757, -0.0518,  0.0603,  0.2375, -0.1872,\n",
       "         0.3281,  0.2299,  0.0373, -0.1801, -0.0330, -0.4423, -0.1511,  0.1204,\n",
       "        -0.0534,  0.0006, -0.0714, -0.1821,  0.0291, -0.2344,  0.0968,  0.0286,\n",
       "        -0.1569,  0.3647,  0.2230,  0.0819,  0.3420,  0.1606, -0.1284,  0.0453,\n",
       "        -0.0867,  0.1897, -0.3756, -0.2782, -0.1539, -0.0495, -0.0076, -0.2035,\n",
       "        -0.0946, -0.1721, -0.0316, -0.0325,  0.0844,  0.4191,  0.4220, -0.2270,\n",
       "         0.0653, -0.1378, -0.0613, -0.0442,  0.1383,  0.0750,  0.0588, -0.1467,\n",
       "         0.1227, -0.0717,  0.2708,  0.0738, -0.0470,  0.0755, -0.0099,  0.0398,\n",
       "         0.2525, -0.0570, -0.0311,  0.2468,  0.1754, -0.1570, -0.5032,  0.0090,\n",
       "         0.4365,  0.3007,  0.2991,  0.1402,  0.0699, -0.0847,  0.3100,  0.2256,\n",
       "         0.0023,  0.2417, -0.1137,  0.3173, -0.0428, -0.2994, -0.2539,  0.0803,\n",
       "         0.0559,  0.0611,  0.2008, -0.0339,  0.0380,  0.0496, -0.0551, -0.0337,\n",
       "        -0.2695,  0.0482, -0.1073,  0.4640, -0.1834, -0.0788,  0.1612, -0.3142,\n",
       "         0.1787,  0.2738,  0.3084,  0.3775,  0.3866, -0.1665,  0.2307,  0.0075,\n",
       "        -0.4145, -0.0826,  0.0497, -0.1481, -0.2664, -0.3021,  0.1657, -0.1821,\n",
       "         0.1797, -0.0367,  0.1903, -0.1451, -0.2368, -0.0179, -0.2790, -0.3284],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.embedding.weight[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Rachel' in src_lang.word2index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"program\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syns[1].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n"
     ]
    }
   ],
   "source": [
    "if syns:\n",
    "    print('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"good\") \n",
    "aset = []\n",
    "for syn in syns:\n",
    "    for temp in syn.lemmas():\n",
    "        if temp.name() in aset:\n",
    "            break\n",
    "        aset.append(temp.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'commodity',\n",
       " 'trade_good',\n",
       " 'full',\n",
       " 'estimable',\n",
       " 'beneficial',\n",
       " 'adept',\n",
       " 'expert',\n",
       " 'dear',\n",
       " 'dependable',\n",
       " 'effective',\n",
       " 'well',\n",
       " 'thoroughly',\n",
       " 'soundly']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

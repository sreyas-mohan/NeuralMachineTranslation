{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "path_to_helper_files = os.path.join('..', 'py_files')\n",
    "base_saved_models_dir = os.path.join('..', 'saved_models' )\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(path_to_helper_files)\n",
    "\n",
    "\n",
    "import global_variables\n",
    "import dataset_helper\n",
    "import nnet_models\n",
    "import train_utilities\n",
    "\n",
    "device = global_variables.device;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_bleu_scores(source_name, target_name, embed_dim, rnn_layers, source_rnn_type, attention):\n",
    "    \n",
    "    MAX_LEN = 48\n",
    "    batchSize = 128\n",
    "\n",
    "    \n",
    "    source_embed_dim = embed_dim\n",
    "    source_hidden_size = embed_dim\n",
    "\n",
    "    target_embed_dim= embed_dim\n",
    "    target_hidden_size = 2*embed_dim\n",
    "    source_rnn_layers = rnn_layers\n",
    "    target_rnn_layers = rnn_layers\n",
    "    \n",
    "    if source_name == 'vi' and target_name == 'en':\n",
    "            target_train_path = '../Data/iwslt-vi-en/train.tok.en'\n",
    "            source_train_path = '../Data/iwslt-vi-en/train.tok.vi'\n",
    "\n",
    "            target_val_path = '../Data/iwslt-vi-en/dev.tok.en'\n",
    "            source_val_path = '../Data/iwslt-vi-en/dev.tok.vi'\n",
    "\n",
    "            target_test_path = '../Data/iwslt-vi-en/test.tok.en'\n",
    "            source_test_path = '../Data/iwslt-vi-en/test.tok.vi'\n",
    "\n",
    "    elif source_name == 'zh' and target_name == 'en':\n",
    "            target_train_path = '../Data/iwslt-zh-en/train.tok.en'\n",
    "            source_train_path = '../Data/iwslt-zh-en/train.tok.zh'\n",
    "\n",
    "            target_val_path = '../Data/iwslt-zh-en/dev.tok.en'\n",
    "            source_val_path = '../Data/iwslt-zh-en/dev.tok.zh'\n",
    "\n",
    "            target_test_path = '../Data/iwslt-zh-en/test.tok.en'\n",
    "            source_test_path = '../Data/iwslt-zh-en/test.tok.zh'\n",
    "    else:\n",
    "            sys.exit(source_name+'->'+target_name+' is invalid!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    saved_models_dir = os.path.join(base_saved_models_dir, source_name+'2'+target_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pth_save_folder_name = source_name+'2'+target_name+'_' + \\\n",
    "                            'source_embed_dim='+str(source_embed_dim) +  \\\n",
    "                            '-source_hidden_size='+str(source_hidden_size) +  \\\n",
    "                            '-source_rnn_layers=' + str(source_rnn_layers) + \\\n",
    "                            '-source_rnn_type='+str(source_rnn_type)+ \\\n",
    "                            '-target_embed_dim='+str(target_embed_dim) + \\\n",
    "                            '-target_hidden_size='+str(target_hidden_size) + \\\n",
    "                            '-target_rnn_layers='+str(target_rnn_layers) + \\\n",
    "                            '-attention='+str(attention);\n",
    "    pth_saved_dir = os.path.join(saved_models_dir, pth_save_folder_name)\n",
    "\n",
    "\n",
    "\n",
    "    config_string = source_name+'2'+target_name+'\\n' + \\\n",
    "                            'source_embed_dim='+str(source_embed_dim) +  \\\n",
    "                            '\\n source_hidden_size='+str(source_hidden_size) +  \\\n",
    "                            '\\n source_rnn_layers=' + str(source_rnn_layers) + \\\n",
    "                            '\\n source_rnn_type='+str(source_rnn_type)+ \\\n",
    "                            '\\n target_embed_dim='+str(target_embed_dim) + \\\n",
    "                            '\\n target_hidden_size='+str(target_hidden_size) + \\\n",
    "                            '\\n target_rnn_layers='+str(target_rnn_layers) + \\\n",
    "                            '\\n attention='+str(attention);\n",
    "    \n",
    "    print(config_string)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    saved_language_model_dir = os.path.join(saved_models_dir, 'lang_obj')\n",
    "\n",
    "\n",
    "\n",
    "    dataset_dict = {'val': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                                                                                            source_path = source_val_path, target_path = target_val_path, \n",
    "                                                                                            lang_obj_path = saved_language_model_dir, val = True), \n",
    "\n",
    "                    'test': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                                                                                            source_path = source_test_path, target_path = target_test_path, \n",
    "                                                                                            lang_obj_path = saved_language_model_dir, val = True)} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dataloader_dict = {'val': DataLoader(dataset_dict['val'], batch_size = 1, \n",
    "                                                                            collate_fn = dataset_helper.vocab_collate_func_val,\n",
    "                                                                    shuffle = True, num_workers=0), \n",
    "                                        'test': DataLoader(dataset_dict['test'], batch_size = 1, \n",
    "                                                                            collate_fn = dataset_helper.vocab_collate_func_val,\n",
    "                                                                    shuffle = True, num_workers=0)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    encoder = nnet_models.EncoderRNN(dataset_dict['val'].source_lang_obj.n_words, \n",
    "                                                                     embed_dim = source_embed_dim, \n",
    "                                                                     hidden_size = source_hidden_size,\n",
    "                                                                     rnn_layers = source_rnn_layers, \n",
    "                                                                     rnn_type = source_rnn_type).to(device);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    decoder = nnet_models.DecoderRNN(dataset_dict['val'].target_lang_obj.n_words, \n",
    "                                                                                            embed_dim = target_embed_dim, \n",
    "                                                                                            hidden_size = target_hidden_size, \n",
    "                                                                                            n_layers = target_rnn_layers, \n",
    "                                                                                            attention = attention).to(device)   \n",
    "\n",
    "\n",
    "    encoder.load_state_dict(torch.load( os.path.join( pth_saved_dir, 'encoder.pth')))\n",
    "    decoder.load_state_dict(torch.load( os.path.join( pth_saved_dir, 'decoder.pth')))\n",
    "\n",
    "    val_bleu_greedy_with_unknown = train_utilities.validation_function(encoder, decoder, dataloader_dict['val'], dataset_dict['val'].target_lang_obj, keep_unk = True)\n",
    "    val_bleu_greedy_without_uknown = train_utilities.validation_function(encoder, decoder, dataloader_dict['val'], dataset_dict['val'].target_lang_obj, keep_unk = False)\n",
    "    val_bleu_beam_with_unknown = train_utilities.validation_beam_search(encoder, decoder, dataloader_dict['val'], dataset_dict['val'].target_lang_obj, beam_size = 3, keep_unk = True)\n",
    "    val_bleu_beam_without_unknown = train_utilities.validation_beam_search(encoder, decoder, dataloader_dict['val'], dataset_dict['val'].target_lang_obj, beam_size = 3, keep_unk = False)\n",
    "\n",
    "    test_bleu_greedy_with_unknown = train_utilities.validation_function(encoder, decoder, dataloader_dict['test'], dataset_dict['test'].target_lang_obj, keep_unk = True)\n",
    "    test_bleu_greedy_without_uknown = train_utilities.validation_function(encoder, decoder, dataloader_dict['test'], dataset_dict['test'].target_lang_obj, keep_unk = False)\n",
    "    test_bleu_beam_with_unknown = train_utilities.validation_beam_search(encoder, decoder, dataloader_dict['test'], dataset_dict['test'].target_lang_obj, beam_size = 3, keep_unk = True)\n",
    "    test_bleu_beam_without_unknown = train_utilities.validation_beam_search(encoder, decoder, dataloader_dict['test'], dataset_dict['test'].target_lang_obj, beam_size = 3, keep_unk = False)\n",
    "\n",
    "    result_string = 'val_bleu_greedy_with_unknown = ' + str(val_bleu_greedy_with_unknown) + '\\n' + \\\n",
    "                    'val_bleu_greedy_without_uknown = ' + str(val_bleu_greedy_without_uknown) + '\\n' + \\\n",
    "                    'val_bleu_beam_with_unknown = ' + str(val_bleu_beam_with_unknown) + '\\n' + \\\n",
    "                    'val_bleu_beam_without_unknown = ' + str(val_bleu_beam_without_unknown) + '\\n' + \\\n",
    "                    'test_bleu_greedy_with_unknown = ' + str(test_bleu_greedy_with_unknown) + '\\n' + \\\n",
    "                    'test_bleu_greedy_without_uknown = ' + str(test_bleu_greedy_without_uknown) + '\\n' + \\\n",
    "                    'test_bleu_beam_with_unknown = ' + str(test_bleu_beam_with_unknown) + '\\n' + \\\n",
    "                    'test_bleu_beam_without_unknown = ' + str(test_bleu_beam_without_unknown) + '\\n' \n",
    "    \n",
    "    print(result_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese to English Without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name = 'zh'\n",
    "target_name = 'en'\n",
    "attention = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_rnn_type_array = ['lstm', 'gru']\n",
    "embed_dim_array = [256, 512]\n",
    "rnn_layers_array = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh2en\n",
      "source_embed_dim=256\n",
      " source_hidden_size=256\n",
      " source_rnn_layers=1\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=256\n",
      " target_hidden_size=512\n",
      " target_rnn_layers=1\n",
      " attention=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sm7582/.conda/envs/denoising/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_bleu_greedy_with_unknown = 4.921381611365873\n",
      "val_bleu_greedy_without_uknown = 4.690058651215148\n",
      "val_bleu_beam_with_unknown = 6.107993596271747\n",
      "val_bleu_beam_without_unknown = 5.854635302290876\n",
      "test_bleu_greedy_with_unknown = 6.18144036343704\n",
      "test_bleu_greedy_without_uknown = 5.952423857991171\n",
      "test_bleu_beam_with_unknown = 7.095033801115852\n",
      "test_bleu_beam_without_unknown = 6.882366559900803\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=256\n",
      " source_hidden_size=256\n",
      " source_rnn_layers=2\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=256\n",
      " target_hidden_size=512\n",
      " target_rnn_layers=2\n",
      " attention=False\n",
      "val_bleu_greedy_with_unknown = 4.137741704180714\n",
      "val_bleu_greedy_without_uknown = 3.890847693626049\n",
      "val_bleu_beam_with_unknown = 5.030571207770108\n",
      "val_bleu_beam_without_unknown = 4.799646526538496\n",
      "test_bleu_greedy_with_unknown = 5.417239701030287\n",
      "test_bleu_greedy_without_uknown = 5.249019417868951\n",
      "test_bleu_beam_with_unknown = 6.429389223091361\n",
      "test_bleu_beam_without_unknown = 6.203615820728647\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=512\n",
      " source_hidden_size=512\n",
      " source_rnn_layers=1\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=512\n",
      " target_hidden_size=1024\n",
      " target_rnn_layers=1\n",
      " attention=False\n",
      "val_bleu_greedy_with_unknown = 5.479287347724563\n",
      "val_bleu_greedy_without_uknown = 5.19996081400239\n",
      "val_bleu_beam_with_unknown = 6.548485980317926\n",
      "val_bleu_beam_without_unknown = 6.258972714060044\n",
      "test_bleu_greedy_with_unknown = 6.62361076845412\n",
      "test_bleu_greedy_without_uknown = 6.4333421817868235\n",
      "test_bleu_beam_with_unknown = 7.636446136614039\n",
      "test_bleu_beam_without_unknown = 7.427471040733164\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=512\n",
      " source_hidden_size=512\n",
      " source_rnn_layers=2\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=512\n",
      " target_hidden_size=1024\n",
      " target_rnn_layers=2\n",
      " attention=False\n",
      "val_bleu_greedy_with_unknown = 5.498817709425976\n",
      "val_bleu_greedy_without_uknown = 5.210698704952246\n",
      "val_bleu_beam_with_unknown = 6.474974359698133\n",
      "val_bleu_beam_without_unknown = 6.1723864134521165\n",
      "test_bleu_greedy_with_unknown = 6.70399606880846\n",
      "test_bleu_greedy_without_uknown = 6.53057354269492\n",
      "test_bleu_beam_with_unknown = 7.365420831754188\n",
      "test_bleu_beam_without_unknown = 7.183257038565517\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=256\n",
      " source_hidden_size=256\n",
      " source_rnn_layers=1\n",
      " source_rnn_type=gru\n",
      " target_embed_dim=256\n",
      " target_hidden_size=512\n",
      " target_rnn_layers=1\n",
      " attention=False\n",
      "val_bleu_greedy_with_unknown = 3.6257842954394635\n",
      "val_bleu_greedy_without_uknown = 3.3324238673928197\n",
      "val_bleu_beam_with_unknown = 4.494993483548692\n",
      "val_bleu_beam_without_unknown = 4.239367172113211\n",
      "test_bleu_greedy_with_unknown = 4.813461492644342\n",
      "test_bleu_greedy_without_uknown = 4.662405364708625\n",
      "test_bleu_beam_with_unknown = 5.539558340446945\n",
      "test_bleu_beam_without_unknown = 5.362467543669871\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=256\n",
      " source_hidden_size=256\n",
      " source_rnn_layers=2\n",
      " source_rnn_type=gru\n",
      " target_embed_dim=256\n",
      " target_hidden_size=512\n",
      " target_rnn_layers=2\n",
      " attention=False\n",
      "val_bleu_greedy_with_unknown = 4.196490343069843\n",
      "val_bleu_greedy_without_uknown = 3.8881158493739933\n",
      "val_bleu_beam_with_unknown = 5.085118281617155\n",
      "val_bleu_beam_without_unknown = 4.819913682281303\n",
      "test_bleu_greedy_with_unknown = 5.282692124064761\n",
      "test_bleu_greedy_without_uknown = 5.1116622295727865\n",
      "test_bleu_beam_with_unknown = 6.019638663412426\n",
      "test_bleu_beam_without_unknown = 5.8220674065945\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=512\n",
      " source_hidden_size=512\n",
      " source_rnn_layers=1\n",
      " source_rnn_type=gru\n",
      " target_embed_dim=512\n",
      " target_hidden_size=1024\n",
      " target_rnn_layers=1\n",
      " attention=False\n",
      "val_bleu_greedy_with_unknown = 4.180483178876497\n",
      "val_bleu_greedy_without_uknown = 3.932305411109842\n",
      "val_bleu_beam_with_unknown = 5.18160239191317\n",
      "val_bleu_beam_without_unknown = 4.949602781105498\n",
      "test_bleu_greedy_with_unknown = 5.276462746763697\n",
      "test_bleu_greedy_without_uknown = 5.125168333323853\n",
      "test_bleu_beam_with_unknown = 6.216650725039346\n",
      "test_bleu_beam_without_unknown = 6.079592177661467\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=512\n",
      " source_hidden_size=512\n",
      " source_rnn_layers=2\n",
      " source_rnn_type=gru\n",
      " target_embed_dim=512\n",
      " target_hidden_size=1024\n",
      " target_rnn_layers=2\n",
      " attention=False\n",
      "val_bleu_greedy_with_unknown = 4.8285114093922115\n",
      "val_bleu_greedy_without_uknown = 4.634318871650986\n",
      "val_bleu_beam_with_unknown = 5.42435819864581\n",
      "val_bleu_beam_without_unknown = 5.146981474532065\n",
      "test_bleu_greedy_with_unknown = 5.662912948275528\n",
      "test_bleu_greedy_without_uknown = 5.475660209598161\n",
      "test_bleu_beam_with_unknown = 6.565180383155108\n",
      "test_bleu_beam_without_unknown = 6.3819944492047975\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for source_rnn_type in source_rnn_type_array:\n",
    "    for embed_dim in embed_dim_array:\n",
    "        for rnn_layers in rnn_layers_array:\n",
    "\n",
    "            print_bleu_scores(source_name, target_name, embed_dim, rnn_layers, source_rnn_type, attention)\n",
    "            print('='*50)\n",
    "            print('\\n \\n \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese to English With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_rnn_type_array = ['lstm']\n",
    "embed_dim_array = [256, 512]\n",
    "rnn_layers_array = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh2en\n",
      "source_embed_dim=256\n",
      " source_hidden_size=256\n",
      " source_rnn_layers=1\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=256\n",
      " target_hidden_size=512\n",
      " target_rnn_layers=1\n",
      " attention=True\n",
      "val_bleu_greedy_with_unknown = 12.024641192759603\n",
      "val_bleu_greedy_without_uknown = 11.604966925131267\n",
      "val_bleu_beam_with_unknown = 15.042286895346253\n",
      "val_bleu_beam_without_unknown = 14.592860300674536\n",
      "test_bleu_greedy_with_unknown = 12.99039073155226\n",
      "test_bleu_greedy_without_uknown = 12.62873926521896\n",
      "test_bleu_beam_with_unknown = 14.177777538180873\n",
      "test_bleu_beam_without_unknown = 13.83382164536157\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=256\n",
      " source_hidden_size=256\n",
      " source_rnn_layers=2\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=256\n",
      " target_hidden_size=512\n",
      " target_rnn_layers=2\n",
      " attention=True\n",
      "val_bleu_greedy_with_unknown = 12.49126416007281\n",
      "val_bleu_greedy_without_uknown = 12.042453114065122\n",
      "val_bleu_beam_with_unknown = 15.186980977963346\n",
      "val_bleu_beam_without_unknown = 14.723540947160055\n",
      "test_bleu_greedy_with_unknown = 12.794585738397913\n",
      "test_bleu_greedy_without_uknown = 12.385528597649058\n",
      "test_bleu_beam_with_unknown = 14.234291295127798\n",
      "test_bleu_beam_without_unknown = 13.854397165329274\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=512\n",
      " source_hidden_size=512\n",
      " source_rnn_layers=1\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=512\n",
      " target_hidden_size=1024\n",
      " target_rnn_layers=1\n",
      " attention=True\n",
      "val_bleu_greedy_with_unknown = 13.63369088664709\n",
      "val_bleu_greedy_without_uknown = 13.10670146381332\n",
      "val_bleu_beam_with_unknown = 16.25571533042744\n",
      "val_bleu_beam_without_unknown = 15.693364762103712\n",
      "test_bleu_greedy_with_unknown = 13.833442756762201\n",
      "test_bleu_greedy_without_uknown = 13.472458436112912\n",
      "test_bleu_beam_with_unknown = 15.519142831754847\n",
      "test_bleu_beam_without_unknown = 15.108041174085034\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "zh2en\n",
      "source_embed_dim=512\n",
      " source_hidden_size=512\n",
      " source_rnn_layers=2\n",
      " source_rnn_type=lstm\n",
      " target_embed_dim=512\n",
      " target_hidden_size=1024\n",
      " target_rnn_layers=2\n",
      " attention=True\n",
      "val_bleu_greedy_with_unknown = 14.481988651156252\n",
      "val_bleu_greedy_without_uknown = 14.046688285986505\n",
      "val_bleu_beam_with_unknown = 17.132485493698617\n",
      "val_bleu_beam_without_unknown = 16.61766978969277\n",
      "test_bleu_greedy_with_unknown = 15.011677793685289\n",
      "test_bleu_greedy_without_uknown = 14.573727312004202\n",
      "test_bleu_beam_with_unknown = 16.369431230455266\n",
      "test_bleu_beam_without_unknown = 15.934639690666026\n",
      "\n",
      "==================================================\n",
      "\n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for source_rnn_type in source_rnn_type_array:\n",
    "    for embed_dim in embed_dim_array:\n",
    "        for rnn_layers in rnn_layers_array:\n",
    "\n",
    "            print_bleu_scores(source_name, target_name, embed_dim, rnn_layers, source_rnn_type, attention)\n",
    "            print('='*50)\n",
    "            print('\\n \\n \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:denoising]",
   "language": "python",
   "name": "conda-env-denoising-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

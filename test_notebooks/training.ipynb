{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_helper_files = os.path.join('..', 'py_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_helper_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import global_variables\n",
    "import dataset_helper\n",
    "import nnet_models\n",
    "import train_utilities\n",
    "\n",
    "device = global_variables.device;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 48\n",
    "batchSize = 128\n",
    "\n",
    "source_embed_dim = 512\n",
    "source_hidden_size = 512\n",
    "source_rnn_layers = 2\n",
    "source_rnn_type  = 'lstm'\n",
    "\n",
    "target_embed_dim= 512\n",
    "target_hidden_size = 1024\n",
    "target_rnn_layers = 2\n",
    "\n",
    "attention = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_path = '../Data/iwslt-vi-en/train.tok.en'\n",
    "vi_train_path = '../Data/iwslt-vi-en/train.tok.vi'\n",
    "\n",
    "en_val_path = '../Data/iwslt-vi-en/dev.tok.en'\n",
    "vi_val_path = '../Data/iwslt-vi-en/dev.tok.vi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_language_model_dir = os.path.join('..', 'lang_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'train': dataset_helper.LanguagePair(source_name = 'vi', target_name='en', \n",
    "                                                    source_path = vi_train_path, target_path = en_train_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir ), \n",
    "               'val': dataset_helper.LanguagePair(source_name = 'vi', target_name='en', \n",
    "                                                    source_path = vi_val_path, target_path = en_val_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir, val = True ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dict = {'train': DataLoader(dataset_dict['train'], batch_size = batchSize, \n",
    "                                    collate_fn = partial(dataset_helper.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "                                shuffle = True, num_workers=0), \n",
    "                  'val': DataLoader(dataset_dict['val'], batch_size = 1, \n",
    "                                    collate_fn = dataset_helper.vocab_collate_func_val,\n",
    "                                shuffle = True, num_workers=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nnet_models.EncoderRNN(dataset_dict['train'].source_lang_obj.n_words, \n",
    "                                 embed_dim = source_embed_dim, \n",
    "                                 hidden_size = source_hidden_size,\n",
    "                                 rnn_layers = source_rnn_layers, \n",
    "                                 rnn_type = source_rnn_type).to(device);\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nnet_models.AttentionDecoderRNN(dataset_dict['train'].target_lang_obj.n_words, \n",
    "                                            embed_dim = target_embed_dim, \n",
    "                                            hidden_size = target_hidden_size, \n",
    "                                            n_layers = target_rnn_layers, \n",
    "                                            attention = attention).to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_optimizer = optim.Adam(encoder.parameters(), lr = 7e-5)\n",
    "# decoder_optimizer = optim.Adam(decoder.parameters(), lr = 7e-5)\n",
    "\n",
    "# enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)\n",
    "\n",
    "# dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-4,  patience=0)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-4,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(ignore_index = global_variables.PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 5.581000069238563, time = 1769.0952169895172\n",
      "epoch 0 val loss = 6.343554078380956, time = 72.39613056182861\n",
      "validation BLEU =  4.951975678850327\n",
      "==================================================\n",
      "epoch 1 train loss = 4.009828028602194, time = 1768.7664515972137\n",
      "epoch 1 val loss = 5.943167093603605, time = 72.17258620262146\n",
      "validation BLEU =  11.239757751534276\n",
      "==================================================\n",
      "epoch 2 train loss = 3.339941236507774, time = 1767.2253789901733\n",
      "epoch 2 val loss = 5.616295772084632, time = 71.92485451698303\n",
      "validation BLEU =  15.861213783504821\n",
      "==================================================\n",
      "epoch 3 train loss = 2.9764972614213963, time = 1767.8095848560333\n",
      "epoch 3 val loss = 5.558829465146508, time = 71.71112585067749\n",
      "validation BLEU =  17.68784112220196\n",
      "==================================================\n",
      "epoch 4 train loss = 2.740610705207905, time = 1768.2375764846802\n",
      "epoch 4 val loss = 5.508859243808015, time = 71.44663572311401\n",
      "validation BLEU =  19.05345164055228\n",
      "==================================================\n",
      "epoch 5 train loss = 2.608559530072781, time = 1764.1676487922668\n",
      "epoch 5 val loss = 5.379563514583918, time = 71.13837504386902\n",
      "validation BLEU =  18.883192254789833\n",
      "==================================================\n",
      "epoch 6 train loss = 2.404267440043392, time = 1763.7462258338928\n",
      "epoch 6 val loss = 5.776960078318389, time = 71.14114189147949\n",
      "validation BLEU =  20.23492414085041\n",
      "==================================================\n",
      "epoch 7 train loss = 2.1416656384339814, time = 1763.1688451766968\n",
      "epoch 7 val loss = 5.442060138004882, time = 71.14116477966309\n",
      "validation BLEU =  22.42816691421552\n",
      "==================================================\n",
      "epoch 8 train loss = 2.0541834541374255, time = 1761.0890054702759\n",
      "epoch 8 val loss = 5.529982639435526, time = 71.18120503425598\n",
      "validation BLEU =  22.8968114332176\n",
      "==================================================\n",
      "epoch 9 train loss = 2.0865723241770766, time = 1763.3577163219452\n",
      "epoch 9 val loss = 5.507256055065675, time = 71.33762264251709\n",
      "validation BLEU =  22.746903825527163\n",
      "==================================================\n",
      "Training completed. Best BLEU is 22.8968114332176\n"
     ]
    }
   ],
   "source": [
    "enc, dec, loss_hist, acc_hist = train_utilities.train_model(encoder_optimizer, decoder_optimizer, \n",
    "                                            encoder, decoder, criterion,\n",
    "                                            \"attention\", dataloader_dict, dataset_dict['train'].target_lang_obj, \n",
    "                                            num_epochs = 10, rm = 0.95,\n",
    "                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), 'encoder_vi_to_eng_sgd_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dec.state_dict(), 'decoder_vi_to_eng_sgd_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr = 3e-4)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr = 3e-4)\n",
    "\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 2.15302320082086, time = 1762.218641281128\n",
      "epoch 0 val loss = 5.616881485766958, time = 71.21776175498962\n",
      "validation BLEU =  24.26047395236699\n",
      "==================================================\n",
      "epoch 1 train loss = 1.9873490552324429, time = 1763.511214017868\n",
      "epoch 1 val loss = 5.57612200590491, time = 71.29489159584045\n",
      "validation BLEU =  22.75959101665562\n",
      "==================================================\n",
      "epoch 2 train loss = 1.8730450260824139, time = 1760.0679602622986\n",
      "epoch 2 val loss = 5.7860374703815305, time = 71.2922670841217\n",
      "validation BLEU =  24.50001153354797\n",
      "==================================================\n",
      "epoch 3 train loss = 1.6666425151214643, time = 1763.1278405189514\n",
      "epoch 3 val loss = 5.753166545247101, time = 71.59293985366821\n",
      "validation BLEU =  24.27148288802906\n",
      "==================================================\n",
      "epoch 4 train loss = 1.604448801665523, time = 1763.908590555191\n",
      "epoch 4 val loss = 5.701294795803914, time = 71.21982789039612\n",
      "validation BLEU =  23.548231030750493\n",
      "==================================================\n",
      "epoch 5 train loss = 1.4770591713760801, time = 1764.2957026958466\n",
      "epoch 5 val loss = 5.801347525379024, time = 71.28975677490234\n",
      "validation BLEU =  23.742872031083518\n",
      "==================================================\n",
      "epoch 6 train loss = 1.4997912250541887, time = 1763.3700602054596\n",
      "epoch 6 val loss = 5.799760265023174, time = 71.20352029800415\n",
      "validation BLEU =  23.648179500635617\n",
      "==================================================\n",
      "epoch 7 train loss = 1.457554568255447, time = 1763.3853390216827\n",
      "epoch 7 val loss = 5.843588141057558, time = 71.24598503112793\n",
      "validation BLEU =  23.626811132771074\n",
      "==================================================\n",
      "epoch 8 train loss = 1.4350335260360898, time = 1763.324675321579\n",
      "epoch 8 val loss = 5.874835370308264, time = 71.24923872947693\n",
      "validation BLEU =  23.795212624218394\n",
      "==================================================\n",
      "epoch 9 train loss = 1.4332790301188887, time = 1763.389145374298\n",
      "epoch 9 val loss = 5.8988061425208524, time = 71.23214173316956\n",
      "validation BLEU =  23.865300593896183\n",
      "==================================================\n",
      "Training completed. Best BLEU is 24.50001153354797\n"
     ]
    }
   ],
   "source": [
    "enc, dec, loss_hist, acc_hist = train_utilities.train_model(encoder_optimizer, decoder_optimizer, \n",
    "                                            encoder, decoder, criterion,\n",
    "                                            \"attention\", dataloader_dict, dataset_dict['train'].target_lang_obj, \n",
    "                                            num_epochs = 10, rm = 0.95,\n",
    "                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc.state_dict(), 'encoder_vi_to_eng_adam_10.pth')\n",
    "torch.save(dec.state_dict(), 'decoder_vi_to_eng_adam_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_helper_files = os.path.join('..', 'py_files')\n",
    "base_saved_models_dir = os.path.join('..', 'saved_models' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_helper_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import global_variables\n",
    "import dataset_helper\n",
    "import nnet_models\n",
    "import train_utilities\n",
    "\n",
    "device = global_variables.device;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name = 'vi'\n",
    "target_name = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 48\n",
    "batchSize = 128\n",
    "\n",
    "source_embed_dim = 512\n",
    "source_hidden_size = 512\n",
    "source_rnn_layers = 2\n",
    "source_rnn_type  = 'lstm'\n",
    "\n",
    "target_embed_dim= 512\n",
    "target_hidden_size = 1024\n",
    "target_rnn_layers = 2\n",
    "\n",
    "attention = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source_name == 'vi' and target_name == 'en':\n",
    "    target_train_path = '../Data/iwslt-vi-en/train.tok.en'\n",
    "    source_train_path = '../Data/iwslt-vi-en/train.tok.vi'\n",
    "    target_val_path = '../Data/iwslt-vi-en/dev.tok.en'\n",
    "    source_val_path = '../Data/iwslt-vi-en/dev.tok.vi'\n",
    "elif source_name == 'zh' and target_name == 'en':\n",
    "    target_train_path = '../Data/iwslt-zh-en/train.tok.en'\n",
    "    source_train_path = '../Data/iwslt-zh-en/train.tok.zh'\n",
    "    target_val_path = '../Data/iwslt-zh-en/dev.tok.en'\n",
    "    source_val_path = '../Data/iwslt-zh-en/dev.tok.zh'\n",
    "else:\n",
    "    sys.exit(source_name+'->'+target_name+' is invalid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models_dir = os.path.join(base_saved_models_dir, source_name+'2'+target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_save_folder_name = source_name+'2'+target_name+'_' + \\\n",
    "                'source_embed_dim='+str(source_embed_dim) + \\\n",
    "                'source_hidden_size='+str(source_hidden_size) + \\\n",
    "                'source_rnn_layers=' + str(source_rnn_layers) + \\\n",
    "                'source_rnn_type='+str(source_rnn_type)+ \\\n",
    "                'target_embed_dim='+str(target_embed_dim) + \\\n",
    "                'target_hidden_size='+str(target_hidden_size) + \\\n",
    "                'target_rnn_layers='+str(target_rnn_layers) + \\\n",
    "                'attention='+str(attention);\n",
    "pth_saved_dir = os.path.join(saved_models_dir, pth_save_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_language_model_dir = os.path.join(saved_models_dir, 'lang_obj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../saved_models/vi2en/lang_obj'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_language_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'train': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                                                    source_path = source_train_path, target_path = target_train_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir ), \n",
    "               'val': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                                                    source_path = source_val_path, target_path = target_val_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir, val = True ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dict = {'train': DataLoader(dataset_dict['train'], batch_size = batchSize, \n",
    "                                    collate_fn = partial(dataset_helper.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "                                shuffle = True, num_workers=0), \n",
    "                  'val': DataLoader(dataset_dict['val'], batch_size = 1, \n",
    "                                    collate_fn = dataset_helper.vocab_collate_func_val,\n",
    "                                shuffle = True, num_workers=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nnet_models.EncoderRNN(dataset_dict['train'].source_lang_obj.n_words, \n",
    "                                 embed_dim = source_embed_dim, \n",
    "                                 hidden_size = source_hidden_size,\n",
    "                                 rnn_layers = source_rnn_layers, \n",
    "                                 rnn_type = source_rnn_type).to(device);\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nnet_models.AttentionDecoderRNN(dataset_dict['train'].target_lang_obj.n_words, \n",
    "                                            embed_dim = target_embed_dim, \n",
    "                                            hidden_size = target_hidden_size, \n",
    "                                            n_layers = target_rnn_layers, \n",
    "                                            attention = attention).to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-4,  patience=0)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-4,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(ignore_index = global_variables.PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, loss_hist, acc_hist = train_utilities.train_model(encoder_optimizer, decoder_optimizer, \n",
    "                                            encoder, decoder, criterion,\n",
    "                                            \"attention\", dataloader_dict, dataset_dict['train'].target_lang_obj, \n",
    "                                            num_epochs = 10, rm = 0.95,\n",
    "                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = train_utilities.validation_function(encoder, decoder, dataloader_dict['val'], \n",
    "                                                   dataset_dict['train'].target_lang_obj , attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(encoder, decoder, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    torch.save(encoder.state_dict(), os.path.join(path, 'encoder.pth'))\n",
    "    torch.save(decoder.state_dict(), os.path.join(path, 'decoder.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(encoder, decoder, pth_save_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr = 3e-4)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr = 3e-4)\n",
    "\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, loss_hist, acc_hist = train_utilities.train_model(encoder_optimizer, decoder_optimizer, \n",
    "                                            encoder, decoder, criterion,\n",
    "                                            \"attention\", dataloader_dict, dataset_dict['train'].target_lang_obj, \n",
    "                                            num_epochs = 10, rm = 0.95,\n",
    "                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_score = train_utilities.validation_function(encoder, decoder, dataloader_dict['val'], \n",
    "                                                   dataset_dict['train'].target_lang_obj , attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_val_score > val_score:\n",
    "    save_models(encoder, decoder, pth_save_folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:denoising]",
   "language": "python",
   "name": "conda-env-denoising-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_helper_files = os.path.join('..', 'py_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_helper_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import global_variables\n",
    "import dataset_helper\n",
    "import nnet_models\n",
    "import train_utilities\n",
    "\n",
    "device = global_variables.device;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 48\n",
    "batchSize = 32\n",
    "hidden_size = 100\n",
    "bi = True\n",
    "lr = 1e-2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_train_path = '../Data/iwslt-vi-en/train.tok.en'\n",
    "vi_train_path = '../Data/iwslt-vi-en/train.tok.vi'\n",
    "\n",
    "en_val_path = '../Data/iwslt-vi-en/dev.tok.en'\n",
    "vi_val_path = '../Data/iwslt-vi-en/dev.tok.vi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_language_model_dir = os.path.join('..', 'lang_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'train': dataset_helper.LanguagePair(source_name = 'vi', target_name='en', \n",
    "                                                    source_path = vi_train_path, target_path = en_train_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir, max_len = MAX_LEN ), \n",
    "               'val': dataset_helper.LanguagePair(source_name = 'vi', target_name='en', \n",
    "                                                    source_path = vi_val_path, target_path = en_val_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir, max_len = MAX_LEN ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dict = {'train': DataLoader(dataset_dict['train'], batch_size = batchSize, \n",
    "                                    collate_fn = partial(dataset_helper.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "                                shuffle = True, num_workers=0), \n",
    "                  'val': DataLoader(dataset_dict['val'], batch_size = batchSize, \n",
    "                                    collate_fn = partial(dataset_helper.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "                                shuffle = True, num_workers=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nnet_models.EncoderRNN(dataset_dict['train'].source_lang_obj.n_words, hidden_size, bi = bi).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nnet_models.DecoderRNN(hidden_size, dataset_dict['train'].target_lang_obj.n_words, bi = bi).to(device)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, dec, loss_hist, acc_hist = train_utilities.train_model(encoder_optimizer, decoder_optimizer, encoder, decoder, criterion,\n",
    "                                              MAX_LEN, 'normal', dataloader_dict, \n",
    "                                              dataset_dict['train'].target_lang_obj, num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

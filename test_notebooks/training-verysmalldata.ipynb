{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_helper_files = os.path.join('..', 'py_files')\n",
    "base_saved_models_dir = os.path.join('..', 'saved_models' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(path_to_helper_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import global_variables\n",
    "import dataset_helper\n",
    "import nnet_models\n",
    "import train_utilities\n",
    "\n",
    "device = global_variables.device;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name = 'vi'\n",
    "target_name = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 48\n",
    "batchSize = 128\n",
    "\n",
    "source_embed_dim = 512\n",
    "source_hidden_size = 512\n",
    "source_rnn_layers = 2\n",
    "source_rnn_type  = 'gru'\n",
    "\n",
    "target_embed_dim= 512\n",
    "target_hidden_size = 1024\n",
    "target_rnn_layers = 2\n",
    "\n",
    "attention = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if source_name == 'vi' and target_name == 'en':\n",
    "    target_train_path = '../Data/iwslt-vi-en/train.tok.en'\n",
    "    source_train_path = '../Data/iwslt-vi-en/train.tok.vi'\n",
    "    target_val_path = '../Data/iwslt-vi-en/dev.tok.en'\n",
    "    source_val_path = '../Data/iwslt-vi-en/dev.tok.vi'\n",
    "elif source_name == 'zh' and target_name == 'en':\n",
    "    target_train_path = '../Data/iwslt-zh-en/train.tok.en'\n",
    "    source_train_path = '../Data/iwslt-zh-en/train.tok.zh'\n",
    "    target_val_path = '../Data/iwslt-zh-en/dev.tok.en'\n",
    "    source_val_path = '../Data/iwslt-zh-en/dev.tok.zh'\n",
    "else:\n",
    "    sys.exit(source_name+'->'+target_name+' is invalid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models_dir = os.path.join(base_saved_models_dir, source_name+'2'+target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_save_folder_name = source_name+'2'+target_name+'_' + \\\n",
    "                'source_embed_dim='+str(source_embed_dim) + \\\n",
    "                'source_hidden_size='+str(source_hidden_size) + \\\n",
    "                'source_rnn_layers=' + str(source_rnn_layers) + \\\n",
    "                'source_rnn_type='+str(source_rnn_type)+ \\\n",
    "                'target_embed_dim='+str(target_embed_dim) + \\\n",
    "                'target_hidden_size='+str(target_hidden_size) + \\\n",
    "                'target_rnn_layers='+str(target_rnn_layers) + \\\n",
    "                'attention='+str(attention);\n",
    "pth_saved_dir = os.path.join(saved_models_dir, pth_save_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_language_model_dir = os.path.join(saved_models_dir, 'lang_obj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {'train': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                                                    source_path = source_train_path, target_path = target_train_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir, \n",
    "                                                    max_num = 100), \n",
    "               'val': dataset_helper.LanguagePair(source_name = source_name, target_name=target_name, \n",
    "                                                    source_path = source_val_path, target_path = target_val_path, \n",
    "                                                    lang_obj_path = saved_language_model_dir, val = True, \n",
    "                                                     max_num = 50) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_dict['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dict = {'train': DataLoader(dataset_dict['train'], batch_size = batchSize, \n",
    "                                    collate_fn = partial(dataset_helper.vocab_collate_func, MAX_LEN=MAX_LEN),\n",
    "                                shuffle = True, num_workers=0), \n",
    "                  'val': DataLoader(dataset_dict['val'], batch_size = 1, \n",
    "                                    collate_fn = dataset_helper.vocab_collate_func_val,\n",
    "                                shuffle = True, num_workers=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nnet_models.EncoderRNN(dataset_dict['train'].source_lang_obj.n_words, \n",
    "                                 embed_dim = source_embed_dim, \n",
    "                                 hidden_size = source_hidden_size,\n",
    "                                 rnn_layers = source_rnn_layers, \n",
    "                                 rnn_type = source_rnn_type).to(device);\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = nnet_models.DecoderRNN(dataset_dict['train'].target_lang_obj.n_words, \n",
    "                                            embed_dim = target_embed_dim, \n",
    "                                            hidden_size = target_hidden_size, \n",
    "                                            n_layers = target_rnn_layers, \n",
    "                                            attention = attention).to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-4,  patience=0)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.25,nesterov=True, momentum = 0.99)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-4,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(ignore_index = global_variables.PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bdef5dc77727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                                             \u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_lang_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                             \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                             enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)\n\u001b[0m",
      "\u001b[0;32m~/Documents/NeuralMachineTranslation/py_files/train_utilities.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(encoder_optimizer, decoder_optimizer, encoder, decoder, loss_fun, attention, dataloader, en_lang, num_epochs, val_every, train_bleu_every, clip, rm, enc_scheduler, dec_scheduler)\u001b[0m\n\u001b[1;32m    204\u001b[0m                                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m                                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder, decoder, loss_hist, acc_hist = train_utilities.train_model(encoder_optimizer, decoder_optimizer, \n",
    "                                            encoder, decoder, criterion,\n",
    "                                            attention, dataloader_dict, dataset_dict['train'].target_lang_obj, \n",
    "                                            num_epochs = 10, rm = 0.95,\n",
    "                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score = train_utilities.validation_function(encoder, decoder, dataloader_dict['val'], \n",
    "                                                   dataset_dict['train'].target_lang_obj , attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(encoder, decoder, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    torch.save(encoder.state_dict(), os.path.join(path, 'encoder.pth'))\n",
    "    torch.save(decoder.state_dict(), os.path.join(path, 'decoder.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(encoder, decoder, pth_saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr = 3e-4)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr = 3e-4)\n",
    "\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-5,factor = 0.5,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, loss_hist, acc_hist = train_utilities.train_model(encoder_optimizer, decoder_optimizer, \n",
    "                                            encoder, decoder, criterion,\n",
    "                                            \"attention\", dataloader_dict, dataset_dict['train'].target_lang_obj, \n",
    "                                            num_epochs = 10, rm = 0.95,\n",
    "                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_score = train_utilities.validation_function(encoder, decoder, dataloader_dict['val'], \n",
    "                                                   dataset_dict['train'].target_lang_obj , attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_val_score > val_score:\n",
    "    save_models(encoder, decoder, pth_saved_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
